{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **SHapley Additive exPlanations Model Interpretability Analysis for Top2Vec Natural Language Processing**: Part 2"
      ],
      "metadata": {
        "id": "ZIhClFk4D3qN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **III. Proposed Methods**: continued"
      ],
      "metadata": {
        "id": "K5u8fGWnEBk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.b. Data Cleaning & Preprocessing:**"
      ],
      "metadata": {
        "id": "utOd0RaUeTax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A natural language processing (NLP) pipeline is built for cleaning and preprocessing the text data. Data is cleaned by stripping newlines, tabs, HTML tags, links, whitespaces, accented characters, special characters, stopwords. Data is preprocessed by converting upper to lower case characters, reducing repeated characters and punctuations, expanding contractions, correcting mis-spelled words, lemmatizing the words, and stemming the words. [[3]](https://towardsdatascience.com/cleaning-preprocessing-text-data-by-building-nlp-pipeline-853148add68a)"
      ],
      "metadata": {
        "id": "TSObRNBdG9az"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial site reference: \n",
        "* [Cleaning & Preprocessing Text Data by Building NLP Pipeline](https://towardsdatascience.com/cleaning-preprocessing-text-data-by-building-nlp-pipeline-853148add68a)\n",
        "by [Kajal Yadav](https://github.com/techykajal/Data-Pre-processing/blob/main/Text_Preprocessing.ipynb)"
      ],
      "metadata": {
        "id": "JQavyUrPGHRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **INSTALLATIONS:**"
      ],
      "metadata": {
        "id": "B7_-SHA87_lX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode # Strips accents from characters.\n",
        "!pip install stopwords # Strips stopwords.\n",
        "!pip install autocorrect # Autocorrects.\n",
        "!pip install nltk # Human language toolkit."
      ],
      "metadata": {
        "id": "pORYvr2H977G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235151b4-92da-4cf7-cf41-41868f867b37"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stopwords\n",
            "  Downloading stopwords-1.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Installing collected packages: stopwords\n",
            "Successfully installed stopwords-1.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[K     |████████████████████████████████| 622 kB 4.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622381 sha256=ea86dfff84cfcef7154351ee297ce2dcf5c7202f645ef5e245e0015c4660e6ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b8/3b/a90246d13090e85394a8a44b78c8abf577c0766f29d6543c75\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPORTED LIBRARIES:**"
      ],
      "metadata": {
        "id": "rU6o6EC08B24"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5C7vXUN54Nen",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b51c6ea9-7852-4dba-d507-92aaee76d669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd  # To read the csv file to a data frame.\n",
        "import numpy as np\n",
        "\n",
        "# Importing Libraries for data cleaning \n",
        "import unidecode \n",
        "import re \n",
        "import time \n",
        "import nltk \n",
        "import stopwords \n",
        "nltk.download('stopwords') \n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from autocorrect import Speller \n",
        "from bs4 import BeautifulSoup \n",
        "from nltk.corpus import stopwords \n",
        "from nltk import word_tokenize \n",
        "import string "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **UPLOAD DATA:**"
      ],
      "metadata": {
        "id": "DkK1IHg1-A3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_depression_pcs = pd.read_csv ('/depression_pcs_data_DAF.csv')\n",
        "df_depression_pcs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Q49wB6w9-DXC",
        "outputId": "fcbd47ed-b927-4ab6-a226-e61427b6570f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0            Documents_from_Depression_or_PCS_Topics  \\\n",
              "0             0  Being depressed feels an awful lot like being ...   \n",
              "1             1  That's what I did when I retrained, but someth...   \n",
              "2             2                           OP said he’s at 5 now so   \n",
              "3             3  First, are you even qualified as in rank, and ...   \n",
              "4             4  Wow thanks for all the info this is great. I'm...   \n",
              "..          ...                                                ...   \n",
              "260         260                               Please, no tie tabs!   \n",
              "261         261  Sorry for being off topic but did you want a s...   \n",
              "262         262                                         Thanks man   \n",
              "263         263     That's mids brain for you, OP tried their best   \n",
              "264         264  I don't know. :( maybe because they think I sh...   \n",
              "\n",
              "     UTC_dates_from_Depression_or_PCS_Topics       Topic  \n",
              "0                               1.414623e+09  depression  \n",
              "1                               1.407341e+09         pcs  \n",
              "2                               1.644846e+09  depression  \n",
              "3                               1.472822e+09         pcs  \n",
              "4                               1.586232e+09  depression  \n",
              "..                                       ...         ...  \n",
              "260                             1.632295e+09         pcs  \n",
              "261                             1.434379e+09         pcs  \n",
              "262                             1.445926e+09  depression  \n",
              "263                             1.636722e+09         pcs  \n",
              "264                             1.467075e+09         pcs  \n",
              "\n",
              "[265 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eafdf595-7051-4cd7-bf6b-c2d76486a49a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Documents_from_Depression_or_PCS_Topics</th>\n",
              "      <th>UTC_dates_from_Depression_or_PCS_Topics</th>\n",
              "      <th>Topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Being depressed feels an awful lot like being ...</td>\n",
              "      <td>1.414623e+09</td>\n",
              "      <td>depression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>That's what I did when I retrained, but someth...</td>\n",
              "      <td>1.407341e+09</td>\n",
              "      <td>pcs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>OP said he’s at 5 now so</td>\n",
              "      <td>1.644846e+09</td>\n",
              "      <td>depression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>First, are you even qualified as in rank, and ...</td>\n",
              "      <td>1.472822e+09</td>\n",
              "      <td>pcs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Wow thanks for all the info this is great. I'm...</td>\n",
              "      <td>1.586232e+09</td>\n",
              "      <td>depression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>260</td>\n",
              "      <td>Please, no tie tabs!</td>\n",
              "      <td>1.632295e+09</td>\n",
              "      <td>pcs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>261</td>\n",
              "      <td>Sorry for being off topic but did you want a s...</td>\n",
              "      <td>1.434379e+09</td>\n",
              "      <td>pcs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>262</td>\n",
              "      <td>Thanks man</td>\n",
              "      <td>1.445926e+09</td>\n",
              "      <td>depression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>263</td>\n",
              "      <td>That's mids brain for you, OP tried their best</td>\n",
              "      <td>1.636722e+09</td>\n",
              "      <td>pcs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>264</td>\n",
              "      <td>I don't know. :( maybe because they think I sh...</td>\n",
              "      <td>1.467075e+09</td>\n",
              "      <td>pcs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>265 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eafdf595-7051-4cd7-bf6b-c2d76486a49a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eafdf595-7051-4cd7-bf6b-c2d76486a49a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eafdf595-7051-4cd7-bf6b-c2d76486a49a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NLP Pipeline:**"
      ],
      "metadata": {
        "id": "i7ooh5UIJsvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove newlines & Tabs\n",
        "def remove_newlines_tabs(text):\n",
        "    \"\"\"\n",
        "    This function will remove all the occurrences of newlines, tabs, and combinations like: \\\\n, \\\\.\n",
        "    \n",
        "    arguments:\n",
        "        input_text: \"text\" of type \"String\". \n",
        "                    \n",
        "    return:\n",
        "        value: \"text\" after removal of newlines, tabs, \\\\n, \\\\ characters.\n",
        "        \n",
        "    Example:\n",
        "    Input : This is her \\\\ first day at this place.\\n Please,\\t Be nice to her.\\\\n\n",
        "    Output : This is her first day at this place. Please, Be nice to her. \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # Replacing all the occurrences of \\n,\\\\n,\\t,\\\\ with a space.\n",
        "    Formatted_text = text.replace('\\\\n', ' ').replace('\\n', ' ').replace('\\t',' ').replace('\\\\', ' ').replace('. com', '.com')\n",
        "    return Formatted_text"
      ],
      "metadata": {
        "id": "L7--fREVeTLN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Strip HTML Tags\n",
        "def strip_html_tags(text):\n",
        "    \"\"\" \n",
        "    This function will remove all the occurrences of html tags from the text.\n",
        "    \n",
        "    arguments:\n",
        "        input_text: \"text\" of type \"String\". \n",
        "                    \n",
        "    return:\n",
        "        value: \"text\" after removal of html tags.\n",
        "        \n",
        "    Example:\n",
        "    Input : This is a nice place to live. <IMG>\n",
        "    Output : This is a nice place to live.  \n",
        "    \"\"\"\n",
        "    # Initiating BeautifulSoup object soup.\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    # Get all the text other than html tags.\n",
        "    stripped_text = soup.get_text(separator=\" \")\n",
        "    return stripped_text"
      ],
      "metadata": {
        "id": "RZsvsQ2Aif7K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Links\n",
        "def remove_links(text):\n",
        "    \"\"\"\n",
        "    This function will remove all the occurrences of links.\n",
        "    \n",
        "    arguments:\n",
        "        input_text: \"text\" of type \"String\". \n",
        "                    \n",
        "    return:\n",
        "        value: \"text\" after removal of all types of links.\n",
        "        \n",
        "    Example:\n",
        "    Input : To know more about this website: kajalyadav.com  visit: https://kajalyadav.com//Blogs\n",
        "    Output : To know more about this website: visit:     \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # Removing all the occurrences of links that starts with https\n",
        "    remove_https = re.sub(r'http\\S+', '', text)\n",
        "    # Remove all the occurrences of text that ends with .com\n",
        "    remove_com = re.sub(r\"\\ [A-Za-z]*\\.com\", \" \", remove_https)\n",
        "    return remove_com"
      ],
      "metadata": {
        "id": "9_niEsIlioE0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Whitespaces\n",
        "def remove_whitespace(text):\n",
        "    \"\"\" This function will remove \n",
        "        extra whitespaces from the text\n",
        "    arguments:\n",
        "        input_text: \"text\" of type \"String\". \n",
        "                    \n",
        "    return:\n",
        "        value: \"text\" after extra whitespaces removed .\n",
        "        \n",
        "    Example:\n",
        "    Input : How   are   you   doing   ?\n",
        "    Output : How are you doing ?     \n",
        "        \n",
        "    \"\"\"\n",
        "    pattern = re.compile(r'\\s+') \n",
        "    Without_whitespace = re.sub(pattern, ' ', text)\n",
        "    # There are some instances where there is no space after '?' & ')', \n",
        "    # So I am replacing these with one space so that It will not consider two words as one token.\n",
        "    text = Without_whitespace.replace('?', ' ? ').replace(')', ') ')\n",
        "    return text"
      ],
      "metadata": {
        "id": "DferarGFiuyl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Accented Characters\n",
        "def accented_characters_removal(text):\n",
        "    # this is a docstring\n",
        "    \"\"\"\n",
        "    The function will remove accented characters from the \n",
        "    text contained within the Dataset.\n",
        "       \n",
        "    arguments:\n",
        "        input_text: \"text\" of type \"String\". \n",
        "                    \n",
        "    return:\n",
        "        value: \"text\" with removed accented characters.\n",
        "        \n",
        "    Example:\n",
        "    Input : Málaga, àéêöhello\n",
        "    Output : Malaga, aeeohello    \n",
        "        \n",
        "    \"\"\"\n",
        "    # Remove accented characters from text using unidecode.\n",
        "    # Unidecode() - It takes unicode data & tries to represent it to ASCII characters. \n",
        "    text = unidecode.unidecode(text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "gxm1OfwQi6we"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for text lowercasing\n",
        "def lower_casing_text(text):\n",
        "    \n",
        "    \"\"\"\n",
        "    The function will convert text into lower case.\n",
        "    \n",
        "    arguments:\n",
        "         input_text: \"text\" of type \"String\".\n",
        "         \n",
        "    return:\n",
        "         value: text in lowercase\n",
        "         \n",
        "    Example:\n",
        "    Input : The World is Full of Surprises!\n",
        "    Output : the world is full of surprises!\n",
        "    \n",
        "    \"\"\"\n",
        "    # Convert text to lower case\n",
        "    # lower() - It converts all upperase letter of given string to lowercase.\n",
        "    text = text.lower()\n",
        "    return text"
      ],
      "metadata": {
        "id": "4_XwSERUkFFo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Code for removing repeated characters and punctuations\n",
        "\n",
        "def reducing_incorrect_character_repeatation(text):\n",
        "    \"\"\"\n",
        "    This Function will reduce repeatition to two characters \n",
        "    for alphabets and to one character for punctuations.\n",
        "    \n",
        "    arguments:\n",
        "         input_text: \"text\" of type \"String\".\n",
        "         \n",
        "    return:\n",
        "        value: Finally formatted text with alphabets repeating to \n",
        "        two characters & punctuations limited to one repeatition \n",
        "        \n",
        "    Example:\n",
        "    Input : Realllllllllyyyyy,        Greeeeaaaatttt   !!!!?....;;;;:)\n",
        "    Output : Reallyy, Greeaatt !?.;:)\n",
        "    \n",
        "    \"\"\"\n",
        "    # Pattern matching for all case alphabets\n",
        "    Pattern_alpha = re.compile(r\"([A-Za-z])\\1{1,}\", re.DOTALL)\n",
        "    \n",
        "    # Limiting all the  repeatation to two characters.\n",
        "    Formatted_text = Pattern_alpha.sub(r\"\\1\\1\", text) \n",
        "    \n",
        "    # Pattern matching for all the punctuations that can occur\n",
        "    Pattern_Punct = re.compile(r'([.,/#!$%^&*?;:{}=_`~()+-])\\1{1,}')\n",
        "    \n",
        "    # Limiting punctuations in previously formatted string to only one.\n",
        "    Combined_Formatted = Pattern_Punct.sub(r'\\1', Formatted_text)\n",
        "    \n",
        "    # The below statement is replacing repeatation of spaces that occur more than two times with that of one occurrence.\n",
        "    Final_Formatted = re.sub(' {2,}',' ', Combined_Formatted)\n",
        "    return Final_Formatted"
      ],
      "metadata": {
        "id": "I1WpLifpkK76"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CONTRACTION_MAP = {\n",
        "\"ain't\": \"is not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"i'd\": \"i would\",\n",
        "\"i'd've\": \"i would have\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'll've\": \"i will have\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"it will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you'll've\": \"you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\",\n",
        "}\n",
        "# The code for expanding contraction words\n",
        "def expand_contractions(text, contraction_mapping =  CONTRACTION_MAP):\n",
        "    \"\"\"expand shortened words to the actual form.\n",
        "       e.g. don't to do not\n",
        "    \n",
        "       arguments:\n",
        "            input_text: \"text\" of type \"String\".\n",
        "         \n",
        "       return:\n",
        "            value: Text with expanded form of shorthened words.\n",
        "        \n",
        "       Example: \n",
        "       Input : ain't, aren't, can't, cause, can't've\n",
        "       Output :  is not, are not, cannot, because, cannot have \n",
        "    \n",
        "     \"\"\"\n",
        "    # Tokenizing text into tokens.\n",
        "    list_Of_tokens = text.split(' ')\n",
        "\n",
        "    # Checking for whether the given token matches with the Key & replacing word with key's value.\n",
        "    \n",
        "    # Check whether Word is in lidt_Of_tokens or not.\n",
        "    for Word in list_Of_tokens: \n",
        "        # Check whether found word is in dictionary \"Contraction Map\" or not as a key. \n",
        "         if Word in CONTRACTION_MAP: \n",
        "                # If Word is present in both dictionary & list_Of_tokens, replace that word with the key value.\n",
        "                list_Of_tokens = [item.replace(Word, CONTRACTION_MAP[Word]) for item in list_Of_tokens]\n",
        "                \n",
        "    # Converting list of tokens to String.\n",
        "    String_Of_tokens = ' '.join(str(e) for e in list_Of_tokens) \n",
        "    return String_Of_tokens"
      ],
      "metadata": {
        "id": "bAz75KJYkMdx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The code for removing special characters\n",
        "def removing_special_characters(text):\n",
        "    \"\"\"Removing all the special characters except the one that is passed within \n",
        "       the regex to match, as they have imp meaning in the text provided.\n",
        "   \n",
        "    \n",
        "    arguments:\n",
        "         input_text: \"text\" of type \"String\".\n",
        "         \n",
        "    return:\n",
        "        value: Text with removed special characters that don't require.\n",
        "        \n",
        "    Example: \n",
        "    Input : Hello, K-a-j-a-l. Thi*s is $100.05 : the payment that you will recieve! (Is this okay?) \n",
        "    Output :  Hello, Kajal. This is $100.05 : the payment that you will recieve! Is this okay?\n",
        "    \n",
        "   \"\"\"\n",
        "    # The formatted text after removing not necessary punctuations.\n",
        "    Formatted_Text = re.sub(r\"[^a-zA-Z0-9:$-,%.?!]+\", ' ', text) \n",
        "    # In the above regex expression,I am providing necessary set of punctuations that are frequent in this particular dataset.\n",
        "    return Formatted_Text"
      ],
      "metadata": {
        "id": "oOeYmPAFkcFG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The code for removing stopwords\n",
        "stoplist = stopwords.words('english') \n",
        "stoplist = set(stoplist)\n",
        "def removing_stopwords(text):\n",
        "    \"\"\"This function will remove stopwords which doesn't add much meaning to a sentence \n",
        "       & they can be remove safely without comprimising meaning of the sentence.\n",
        "    \n",
        "    arguments:\n",
        "         input_text: \"text\" of type \"String\".\n",
        "         \n",
        "    return:\n",
        "        value: Text after omitted all stopwords.\n",
        "        \n",
        "    Example: \n",
        "    Input : This is Kajal from delhi who came here to study.\n",
        "    Output : [\"'This\", 'Kajal', 'delhi', 'came', 'study', '.', \"'\"] \n",
        "    \n",
        "   \"\"\"\n",
        "    # repr() function actually gives the precise information about the string\n",
        "    text = repr(text)\n",
        "    # Text without stopwords\n",
        "    No_StopWords = [word for word in word_tokenize(text) if word.lower() not in stoplist ]\n",
        "    # Convert list of tokens_without_stopwords to String type.\n",
        "    words_string = ' '.join(No_StopWords)    \n",
        "    return words_string"
      ],
      "metadata": {
        "id": "2HHm8L52kgdD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The code for spelling corrections\n",
        "def spelling_correction(text):\n",
        "    ''' \n",
        "    This function will correct spellings.\n",
        "    \n",
        "    arguments:\n",
        "         input_text: \"text\" of type \"String\".\n",
        "         \n",
        "    return:\n",
        "        value: Text after corrected spellings.\n",
        "        \n",
        "    Example: \n",
        "    Input : This is Oberois from Dlhi who came heree to studdy.\n",
        "    Output : This is Oberoi from Delhi who came here to study.\n",
        "      \n",
        "    \n",
        "    '''\n",
        "    # Check for spellings in English language\n",
        "    spell = Speller(lang='en')\n",
        "    Corrected_text = spell(text)\n",
        "    return Corrected_text"
      ],
      "metadata": {
        "id": "DGh6nwsAlU_3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The code for lemmatization\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "def lemmatization(text):\n",
        "    \"\"\"This function converts word to their root words \n",
        "       without explicitely cut down as done in stemming.\n",
        "    \n",
        "    arguments:\n",
        "         input_text: \"text\" of type \"String\".\n",
        "         \n",
        "    return:\n",
        "        value: Text having root words only, no tense form, no plural forms\n",
        "        \n",
        "    Example: \n",
        "    Input : text reduced \n",
        "    Output :  text reduce\n",
        "    \n",
        "   \"\"\"\n",
        "    # Converting words to their root forms\n",
        "    lemma = [lemmatizer.lemmatize(w,'v') for w in w_tokenizer.tokenize(text)]\n",
        "    return lemma"
      ],
      "metadata": {
        "id": "xo-Uz-5LlXgF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing main function to merge all the preprocessing steps.\n",
        "def text_preprocessing(text, accented_chars=True, contractions=True, lemmatization = True,\n",
        "                        extra_whitespace=True, newlines_tabs=True, repeatition=True, \n",
        "                       lowercase=True, punctuations=True, mis_spell=True,\n",
        "                       remove_html=True, links=True,  special_chars=True,\n",
        "                       stop_words=True):\n",
        "    \"\"\"\n",
        "    This function will preprocess input text and return\n",
        "    the clean text.\n",
        "    \"\"\"\n",
        "        \n",
        "    if newlines_tabs == True: #remove newlines & tabs.\n",
        "        Data = remove_newlines_tabs(text)\n",
        "        \n",
        "    if remove_html == True: #remove html tags\n",
        "        Data = strip_html_tags(Data)\n",
        "        \n",
        "    if links == True: #remove links\n",
        "        Data = remove_links(Data)\n",
        "        \n",
        "    if extra_whitespace == True: #remove extra whitespaces\n",
        "        Data = remove_whitespace(Data)\n",
        "        \n",
        "    if accented_chars == True: #remove accented characters\n",
        "        Data = accented_characters_removal(Data)\n",
        "        \n",
        "    if lowercase == True: #convert all characters to lowercase\n",
        "        Data = lower_casing_text(Data)\n",
        "        \n",
        "    if repeatition == True: #Reduce repeatitions   \n",
        "        Data = reducing_incorrect_character_repeatation(Data)\n",
        "        \n",
        "    if contractions == True: #expand contractions\n",
        "        Data = expand_contractions(Data)\n",
        "    \n",
        "    if punctuations == True: #remove punctuations\n",
        "        Data = removing_special_characters(Data)\n",
        "    \n",
        "    stoplist = stopwords.words('english') \n",
        "    stoplist = set(stoplist)\n",
        "    \n",
        "    if stop_words == True: #Remove stopwords\n",
        "        Data = removing_stopwords(Data)\n",
        "        \n",
        "    spell = Speller(lang='en')\n",
        "    \n",
        "    if mis_spell == True: #Check for mis-spelled words & correct them.\n",
        "        Data = spelling_correction(Data)\n",
        "        \n",
        "    w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    # Converts words to lemma form. \n",
        "    if lemmatization == False: # Whether to overwrite existing lemmas. Defaults to `False`.\n",
        "        Data = lemmatization(Data)\n",
        "    \n",
        "           \n",
        "    return Data\n"
      ],
      "metadata": {
        "id": "L1XwOxd2lwDv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-processing for Content\n",
        "List_Content = df_depression_pcs['Documents_from_Depression_or_PCS_Topics'].to_list()\n",
        "Final_Article = []\n",
        "Complete_Content = []\n",
        "for article in List_Content:\n",
        "    Processed_Content = text_preprocessing(article) #Cleaned text of Content attribute after pre-processing\n",
        "    Final_Article.append(Processed_Content)\n",
        "Complete_Content.extend(Final_Article)\n",
        "df_depression_pcs['Processed_comments'] = Complete_Content\n"
      ],
      "metadata": {
        "id": "uOkCVV_coOwQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_depression_pcs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "QV1f2nN0yyfO",
        "outputId": "718e39f8-55f5-4c61-b780-8f05d4f98c1d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0            Documents_from_Depression_or_PCS_Topics  \\\n",
              "0             0  Being depressed feels an awful lot like being ...   \n",
              "1             1  That's what I did when I retrained, but someth...   \n",
              "2             2                           OP said he’s at 5 now so   \n",
              "3             3  First, are you even qualified as in rank, and ...   \n",
              "4             4  Wow thanks for all the info this is great. I'm...   \n",
              "..          ...                                                ...   \n",
              "260         260                               Please, no tie tabs!   \n",
              "261         261  Sorry for being off topic but did you want a s...   \n",
              "262         262                                         Thanks man   \n",
              "263         263     That's mids brain for you, OP tried their best   \n",
              "264         264  I don't know. :( maybe because they think I sh...   \n",
              "\n",
              "     UTC_dates_from_Depression_or_PCS_Topics       Topic  \\\n",
              "0                               1.414623e+09  depression   \n",
              "1                               1.407341e+09         pcs   \n",
              "2                               1.644846e+09  depression   \n",
              "3                               1.472822e+09         pcs   \n",
              "4                               1.586232e+09  depression   \n",
              "..                                       ...         ...   \n",
              "260                             1.632295e+09         pcs   \n",
              "261                             1.434379e+09         pcs   \n",
              "262                             1.445926e+09  depression   \n",
              "263                             1.636722e+09         pcs   \n",
              "264                             1.467075e+09         pcs   \n",
              "\n",
              "                                    Processed_comments  \n",
              "0    `` depressed feels awful lot like alone lot ti...  \n",
              "1    'that retained , something say may also need a...  \n",
              "2                                         'op said 5 '  \n",
              "3    'first , even qualified rank , per ? saw afd k...  \n",
              "4    'wow thanks info great . gon na get right away...  \n",
              "..                                                 ...  \n",
              "260                             'please , tie tabs ! '  \n",
              "261             'sorry topic want statewide follow ? '  \n",
              "262                                      'thanks man '  \n",
              "263                  'that mid brain , op tried best '  \n",
              "264  ' know . : ( maybe think google tried . looked...  \n",
              "\n",
              "[265 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71161003-4f4e-4440-99a7-e4be20259260\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Documents_from_Depression_or_PCS_Topics</th>\n",
              "      <th>UTC_dates_from_Depression_or_PCS_Topics</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Processed_comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Being depressed feels an awful lot like being ...</td>\n",
              "      <td>1.414623e+09</td>\n",
              "      <td>depression</td>\n",
              "      <td>`` depressed feels awful lot like alone lot ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>That's what I did when I retrained, but someth...</td>\n",
              "      <td>1.407341e+09</td>\n",
              "      <td>pcs</td>\n",
              "      <td>'that retained , something say may also need a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>OP said he’s at 5 now so</td>\n",
              "      <td>1.644846e+09</td>\n",
              "      <td>depression</td>\n",
              "      <td>'op said 5 '</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>First, are you even qualified as in rank, and ...</td>\n",
              "      <td>1.472822e+09</td>\n",
              "      <td>pcs</td>\n",
              "      <td>'first , even qualified rank , per ? saw afd k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Wow thanks for all the info this is great. I'm...</td>\n",
              "      <td>1.586232e+09</td>\n",
              "      <td>depression</td>\n",
              "      <td>'wow thanks info great . gon na get right away...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>260</td>\n",
              "      <td>Please, no tie tabs!</td>\n",
              "      <td>1.632295e+09</td>\n",
              "      <td>pcs</td>\n",
              "      <td>'please , tie tabs ! '</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>261</td>\n",
              "      <td>Sorry for being off topic but did you want a s...</td>\n",
              "      <td>1.434379e+09</td>\n",
              "      <td>pcs</td>\n",
              "      <td>'sorry topic want statewide follow ? '</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>262</td>\n",
              "      <td>Thanks man</td>\n",
              "      <td>1.445926e+09</td>\n",
              "      <td>depression</td>\n",
              "      <td>'thanks man '</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>263</td>\n",
              "      <td>That's mids brain for you, OP tried their best</td>\n",
              "      <td>1.636722e+09</td>\n",
              "      <td>pcs</td>\n",
              "      <td>'that mid brain , op tried best '</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>264</td>\n",
              "      <td>I don't know. :( maybe because they think I sh...</td>\n",
              "      <td>1.467075e+09</td>\n",
              "      <td>pcs</td>\n",
              "      <td>' know . : ( maybe think google tried . looked...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>265 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71161003-4f4e-4440-99a7-e4be20259260')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-71161003-4f4e-4440-99a7-e4be20259260 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-71161003-4f4e-4440-99a7-e4be20259260');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Cleaned_Depression_PCS_Data = df_depression_pcs.to_csv('Cleaned_Depression_PCS_Data_DAF.csv', index = False)"
      ],
      "metadata": {
        "id": "6axIGz-H1Xa2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('Cleaned_Depression_PCS_Data_DAF.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "a6t6kR8CQBMz",
        "outputId": "705d0dc9-d7be-4925-80be-08c1c26dd3c5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0294a1de-cb54-476c-b9a0-0ea1d132853c\", \"Cleaned_Depression_PCS_Data_DAF.csv\", 94590)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}